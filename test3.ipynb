{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Google Cloud and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Sathwik Chenna Madhavuni\n",
    "\n",
    "Andrew ID: schennam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial will introduce you to Google Cloud Compute Engine and TensorFlow. We will go through the basics of tensorflow and implement linear regression, classification and neural networks in tensorflow and run them on Google standalone compute engine. Then, we will submit our model to google cloud which can take handle large amounts of data and computing requirement. Often times, Companies buy cloud resources from Goolge or AWS for their Data Science infrastucture instead of buying on-the-premise hardware. We will know how do they implement their ML projects using google cloud.\n",
    "\n",
    "Note: This tutorial assumes that you know about linear regression, classification and mnist digit classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tutorial content\n",
    "\n",
    "In this tutorial, we will learn how to setup the Google VM ( Compute Engine ) and start the Datalab ( Jupyter Notebook ), and then run the ML models using Tensorflow.\n",
    "\n",
    "We will be using sample data for the ML models. Our focus here is to know the implementation of ML models using Tensorflow than data, hence sample data has been chosen and more focus is given to implementation part. However, for nerual networks, the classical example of MNIST numbers identification has been chosen.\n",
    "\n",
    "\n",
    "We will cover the following topics in this tutorial:\n",
    "\n",
    "    Setting up the Google Cloud Platform Account\n",
    "    Starting the Compute Engine VM \n",
    "    Connecting to Datalab\n",
    "    Basics of Tensorflow\n",
    "    Linear Regression \n",
    "    Classification\n",
    "    Neural Networks\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Google Cloud Platform Account - Free Trial\n",
    "\n",
    "Follow the instructions mentioned here to set up a google cloud platform account https://codelabs.developers.google.com/codelabs/cpb100-free-trial/index.html#0 \n",
    "\n",
    "you need to have a google account and follow the steps carefully.\n",
    "You will be given a credit of $300 valid for one year.\n",
    "\n",
    "Required Time: 10 mins\n",
    "\n",
    "You should get a GCP homepage like this:\n",
    "\n",
    "<img src=\"gcp_home.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the Compute Engine VM \n",
    "\n",
    "After you have successfully set up your account, start the compute engine by following these instructions https://codelabs.developers.google.com/codelabs/dataeng-machine-learning/index.html?index=#0 \n",
    "\n",
    "or you can start from the homepage as follows as: \n",
    "\n",
    "HomePage -> Options -> Compute -> Compute Engine -> VM Instance -> Create new instance \n",
    "\n",
    "<img src=\"vm.png\">\n",
    "\n",
    "Note: Before creating any instance, please make sure whether the selected features of the product(or instance) are within the free trial limits or not. Google cloud will prompt you when you try to activate billable services but be careful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Datalab\n",
    "\n",
    "Datalab is like a Jupyter Notebook where you run your Python code and see the results. In google terms, Jupyter Notebook is Datalab, but with most Google-like features embedded into it. After the VM is started, follow these instructions to start the Datalab\n",
    "\n",
    "Step 1: In Google Cloud Shell, type:\n",
    "*gcloud compute zones list*\n",
    "\n",
    "Pick a zone in a geographically closeby region.\n",
    "\n",
    "Step 2: In Google Cloud Shell, type:\n",
    "*datalab create dataengvm --zone USER_INPUT_SELECTED_ZONE_NAME*\n",
    "\n",
    "This step will take about 3-5 minutes to start. Follow the prompts during this process. If you are not yet familiar with Datalab, follow this:\n",
    "\n",
    "<img src=\"datalab.png\">\n",
    "\n",
    "For more information: https://codelabs.developers.google.com/codelabs/dataeng-machine-learning/index.html?index=#2 \n",
    "\n",
    "Or, if you are starting the VM using UI, then follow these instructions:\n",
    "Google Cloud Platform console -> Options -> Products and Services -> Compute Engine -> VM Instances -> Start the VM\n",
    "\n",
    "After the VM starts, Open the google cloud shell, and run the following command to get the datalab:\n",
    "datalab connect --zone us-east1-b --port 8081 dataengvm\n",
    "Note: this command is not specified in the intial instructions, it took me time to get this command. Hence I am providing it explicitly so that you do not create a VM repeatedly. You need to create a VM only once, and the reuse it whenever you want. Also, dont forget to stop it when you are done with your work.\n",
    "\n",
    "<img src=\"command.png\">\n",
    "\n",
    "Successful datalab opening in browswer should look like this:\n",
    "\n",
    "<img src=\"gcd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are all set for building ML models in Google compute engine datalab. The following exercises will explain how to implement the basic models in tensorflow. Note: Here we are focussing on the implementation ( syntax, functions, the details of programming in tensorflow ) of models in tensorflow and not really on the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Tensorflow\n",
    "\n",
    "TensorFlow is an open source software library for numerical computation using data-flow graphs. It was originally developed by the Google Brain Team within Google's Machine Intelligence research organization for machine learning and deep neural networks research.\n",
    "\n",
    "TensorFlow is cross-platform. It runs on nearly everything: GPUs and CPUs—including mobile and embedded platforms—and even tensor processing units (TPUs), which are specialized hardware to do tensor math on. \n",
    "\n",
    "For more info: https://www.tensorflow.org/\n",
    "\n",
    "Following picture shows the interface of tensorflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1tensorflow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow allows to build data flow graphs and allows us to better apply numerical computation on it in a easier way. Thus, it helps us to build deep neural networks. A deep neural network is neural network having two or more hidden layers. Data is passed in the form of multidimensional arrays which are called Tensors. Within each graph, each node represents mathematical operations and edges of graphs represents tensors. \n",
    "\n",
    "Tensor: n-dimensional array \n",
    "\n",
    "Flow: data flow computational framework ( like mapreduce )\n",
    "\n",
    "for example: \n",
    "\n",
    "<img src=\"graph.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will see how numerical computation like addition, subtraction and multiplication are done in Tensorflow.\n",
    "\n",
    "The way the tensorflow works is that first, we need to build a computational graph or a model .The model could be any number of nodes from 1 to n. Then after the model is ready then, we create a tensorflow session and start the session with the input nodes. When session's run method is called then only all the computation will happen. ( lazy evaluation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# build computational graph\n",
    "a = tf.placeholder(tf.int16)\n",
    "b = tf.placeholder(tf.int16)\n",
    "#Placeholders are like the variable with no value on them but later we can place the value on it. \n",
    "#tf.Placeholder is used to feed actual training data\n",
    "\n",
    "#Add logic\n",
    "addition = tf.add(a, b)\n",
    "subtraction = tf.subtract(a, b)\n",
    "multiply = tf.multiply(a, b)\n",
    "\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "#Since first we build a model so we have to run the initializer in the session first.\n",
    "\n",
    "# create session and run the graph\n",
    "#To run them we need to create a tensorflow session as: \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"Addition: %i\" % sess.run(addition, feed_dict={a: 2, b: 3}))\n",
    "    print (\"Subtraction: %i\" % sess.run(subtraction, feed_dict={a: 2, b: 3}))\n",
    "    print (\"Multiply: %i\" % sess.run(multiply, feed_dict={a: 2, b: 3}))\n",
    "\n",
    "# close session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using Gradient Descent\n",
    "\n",
    "First, we will implement the linear regression in tensorflow using gradient descent optimization.\n",
    "and then we will use the estimator.\n",
    "\n",
    "Linear regression is a supervised machine learning approach for modeling a linear relationship between a dependent variable and one or more independent variables. In very simple words, it is an approach to create a straight line or a model from discrete values and generate an output which is continuous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500 cost= 0.094137512 weight= 0.3229541 constant= 0.2737156\n",
      "Epoch : 1000 cost= 0.081993841 weight= 0.289328 constant= 0.5156199\n",
      "Epoch : 1500 cost= 0.078443743 weight= 0.27111486 constant= 0.6466439\n",
      "Epoch : 2000 cost= 0.077409074 weight= 0.26125044 constant= 0.7176078\n",
      "Epoch : 2500 cost= 0.077109143 weight= 0.25590637 constant= 0.7560524\n",
      "Epoch : 3000 cost= 0.077023111 weight= 0.2530115 constant= 0.77687895\n",
      "Optimization Finished!\n",
      "Training cost= 0.07702311 W= 0.2530115 b= 0.77687895 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFKCAYAAAAuZDceAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XlclOX6BvBrmGHfQgUhKY8bkmho\nuZELgj+XMlOULC2PW0puQKCCmR2ro1mKgp0WTC3tlJUk0nIqS3LLct+OQmRmpiKgouwDM7y/PzhN\nvTLsM/PMcn0/n/PHe/POzO0Th2ued3sUkiRJICIiImHsRDdARERk6xjGREREgjGMiYiIBGMYExER\nCcYwJiIiEoxhTEREJJhK1AcXFBQ3+TVeXi4oLCwzQjdUH467GBx3MTjuYtjKuHt7u+utW9TMWKVS\nim7BJnHcxeC4i8FxF8PWx92iwpiIiMgaMYyJiIgEYxgTEREJxjAmIiISjGFMREQkGMOYiIhIMIYx\nERGRYAzj2+Tn5yExMQ6PPx6BCRPGIDl5NaqqqvTue+1aAZ57blGD77lgQTSKi5v+kBMA2LgxFR98\n8F6D+w0bNqjenxcXF2P79m3N6oGIiIzLosPYMT0NXqEhaOPnBa/QEDimp7Xo/SRJwpIlCzFo0BB8\n+GE6tm7djvLyMqxf/0atfTUaDdq08cY///lqg++7evU6uLvrf+qKqZSUFCM9nWFMRGSOGnwcplqt\nxhNPPIHKykpotVqMGDEC0dHRsn22b9+OV199FW3btgUAPPnkk3j00UeN0/H/OKanwSNqum5blXUG\nHlHTUQRAHRHZrPc8evQwHBwcMWrUIwAApVKJ6Og4PProGMyYEYXMzG9w4MB+VFZWoqKiHIsXP49F\ni2Lx3nsfo6KiAsuXL8PFixfQvn0H5OZeQXx8AgIDuyEycjQ2bHgP5eVlWLAgGvfe2xOnT5+Ct7c3\nVq5MgqOjEz79NB2ffpqOqqoq+Pv7Y+nSl+Dk5FRnr1euXMYLLzwHrVaLfv1CdPWysjIsXhyP4uIi\naDQazJw5G4MGDcFbb72Gy5cvY+rUSejTpx+mTZupdz8iIjK9BsPYwcEBmzdvhqurK6qqqjBp0iQM\nHjwYPXv2lO330EMP4fnnnzdao7dzSU7SX09Z0+ww/vXX8+jaNVBWc3V1Q9u2bXHp0u8AgDNnTmPz\n5q3w8PBEbu4V3X7bt2+Du7s7Nm/+EOfPn8O0aU/o/YxLl37HsmXLkZDwHJYuTcTu3ZkYMeIhhIaG\n4ZFHIgAA69e/gc8/34HIyMfr7DUlZTXGjh2PBx98GJ988rGu7uDggBUrVsHV1Q03b95EVNRUDBwY\niqefno/z53/Bu+9+AKBmZq9vP4VC0ayxIyKyJmcv3EBJeRV6B/rAzgR/FxsMY4VCAVdXVwA1f8A1\nGo1Z/MFW5mQ3qd4YkiTp/bdJEnT1Pn36wcPDs9Y+p0+fwKOPTgQAdOzYGZ06ddb7GX5+d6JLl64A\ngK5dA3WBfv78L3j77TdRUlKM8vJy9O3bv95eT58+heXLVwEARo58CG+99ZruZ6mpr+PkyeNQKOxQ\nUFCAGzeu630Pffu1bt2m3s8lIrJm6iotYtfth7pKCwBIvtsLHq4ORv/cRq3apNVqMW7cOFy8eBGT\nJk1CcHBwrX127tyJw4cPo0OHDli8eDH8/PzqfU8vL5dmPRhct+JFt27A6dO1fq7o1q3OVTEa0qtX\nd7z++h7Z60tKSnDtWj6CgwNx5cqv8PLy0P1crXaFSqWEt7c77O2V8PR01v1MpVLijjtc4O3tDqXS\nDq1bu6KsTAFnZyfdPh4eLigrK4O3tztWrnwRb7zxBgIDA7F9+3YcOnQI3t7ucHV1hIuLY61/k52d\nAt7e7lCpVHB2VkChqNnevn07ystLkJGxA/b29ggPD4ebmz0Ae12vAOrcr66xa+6YUstw3MXguIsh\netw/338eqel/5srQPneh099am+SzGxXGSqUSGRkZKCoqwty5c5GTk4OAgADdz8PCwvDwww/DwcEB\nW7duRUJCArZs2VLvezZnqSxvb3fd0ouO856RnTP+Q9HcWKibsTwjAHTu3B3FxaXYsmUrHnzwYWi1\nWqxe/TJGjBiFkhINiosrUF5eqevhxo1SaDRaFBQUIzCwO9LTP0WnTkH49dfz+Omnn3DzZhkKCoqh\n1Vbj+vVSlJeX6fYHgJISNcrL1SgoKEZJSQns7JyRm1uITz5Jh7e3DwoKilFaqkZ1tbLWkpNBQT3w\n4YefYMSIh5CengZJklBQUIzc3GtwcXHHzZsVOHZsPy5fvowbN0rh4uKCoqJi3fvUtZ+jY+2x++u4\nk+lw3MXguIshctxvlVbimdf2y2pv7V6NO1N+gObFQJTFxjf79OftDLKEooeHB/r164d9+/bJ6l5e\nXnBwqJnGT5gwAWfOnGlmm42njohEUeomaLp1h6RSQdOtO4pSN7VowBQKBVasWIXvvtuFxx+PwMSJ\n4+Dg4ICoqLkNvjYi4lHcvFmIKVMex/vvb0anTl3g6urW6M9+6qnZmDVrKmJj56B9+781uH9MzAJs\n374NTz31d5SUlOjqw4c/iOzsLMyYMRk7d36pey9PzzvQo0cwJk+egNdfT6lzPyIiW/LBNzmyIB7X\nuhyfrRmLdsf2Q6HV6i4ObundOg1RSJIk1bfDjRs3oFKp4OHhgYqKCkyfPh0zZ85EWFiYbp/8/Hz4\n+PgAAL755hu8/fbb+Pjjj+t6SwBo1jcgc/7GqtVqodFo4OjoiMuXLyEmZja2bt0Oe3t70a21mDmP\nuzXjuIvBcRfD1ON+5VopnttwUFZ7LXYQ/EcMhiqr9oRS0607CncfaPHn1jUzbvAwdX5+PhITE6HV\naiFJEkaOHImwsDCkpKSge/fuGDp0KN577z1kZmZCqVTC09MTL7/8cosbtjRqdQXmz38aGo0GgIT4\n+ESrCGIiImsiSRLWfHQCZy4U6mpPPXwPHuhec52TMS4ObowGZ8bGYm0zY2vGcReD4y4Gx10MU4x7\n1oUbWPXhCd12aw9HvBwVApXyzzO2XqEh5jkzJiIismRVmmokpv6AwmK1rrZoYi8EtveqtW9ZbLze\ni4PLYuKM2iPDmIiIrNb3p3Ox8Yss3Xb3jq3wzKPBdT4vQx0RiSLUPEBKmZMNbUAgymLiDHY1dV0Y\nxkREZHVKyqsQnSK/8+efT/XDnW1cG3ytOiLS6OF7O4YxERFZlfS95/HZgQu67eF97sLjQ7uIa6gR\nLHrVJmMYPLgvpk6dpPtfbu4VZGefRXJyzaMnjx07gtOnT+r237t3N3799XyTP6euJQ//qDd2eUYi\nIqqRf7Mc01dmyoJ47fyBZh/EAGfGtTg6OuoWU/iDn9+dCAzsBgA4fvwonJ1d0KNHzSNB9+3bjQce\nGIgOHToatI/GLs9IRGTrJEnCmxlncCQ7X1d7cngAwu/zF9hV0zCMG+HYsSP48MN/45lnFiEjYzvs\n7Oywc+eXiImJx/79e3HixDFs3rwJy5fXhGdS0iu4ebMQTk5OSEh4Du3b/63OJQ/rkpt7Rbc843/+\n8xn279+LiooKXLlyCYMHD8GcOTEAgEOHfsTGjamoqqrEnXf649ln/wEXFxejjgcRkbn45cotLN9y\nVLft7KjEmnkD4Wjf9LUPRDLbMP448xwO/+VbDgAolQpotc2/LbpPoA8mhOtfTekParUaU6dOAlAz\nI3755dW6n/n53YkxY8bB2dkFkyZNBgAMHDgYDzwwEGFh/wcAiImZjQULFuOuu+7GmTP/RVLSSqxb\n91adSx421s8/5+Cdd96Hvb09Jk0aj/HjH4OjoxM2b96I5OQ34OzsjH//+1189NH7mDZtZpPfn4jI\nkBzT0+CSnPTnFckGfL4zAGirq7Fs02Fcvlaqq8VE3ovgzpa58pzZhrEo+g5TN1ZZWRlOnz6FpUsT\ndbWqqkoA9S952Bi9e/eBm1vNs67/9reOuHr1KkpKinHhwnnMnj0DAKDRVCEoqEezeiciMhTH9DTZ\nvbp/PN+5CDBIIB/JzscbO/6r2+7UzgOLn7zfJOsOG4vZhvGE8M61ZrHm/mQcSaqGu7tbs8O8Pn99\ntKZSaQetVgNJktC7dz+88MIKg38eEVFzuSQn6a+nrGlRGJerNZi3di/+enz0H1P7oL2v5S95yaup\nm8jFxRXl5WV/2a5ZkxgAXF3d4OfXDpmZ3wKouajg559zAAA9etyLXbt2AgB27vzKIL0EBfXA6dMn\ncenS7wCAiooKXLz4m0Hem4iouYzxfOevDl7E3L8E8cB7/bApMdwqghhgGDfZgAGDsHfvd5g6dRJO\nnjyOoUOHY+vW9zBt2iRcvnwJzz//Ej7/PANTpkzE5MkTsH//HgB1L3nYEl5eXliyZBmWLVuCKVMe\nR1TUVFy8eMEg701E1FzagMAm1etTWKzG9JWZ+Pi7c7ra6jkPYPpD9zS7P3PEhSKoQRx3MTjuYnDc\nW+72c8Z/qG/NeX3j/u6X2dh78opuO3JIJzzUv71hmzUxLhRBREQm0dLnO1/MK8aydw7Laq8/MxjO\njtYbWdb7LyMiImGa83znaknCyveP4dylW7ra02OC0PeetoZuz+wwjImISLij2XlY9vaPum2/1i54\nYXpf2VrD1oxhTEREwlRWaRH/+vcordDoas8+eT86+3sK7Mr0GMZERCTE7hOXseWrn3Tb9wd4Y05E\n9zrXGrZmDGMiIjKporJKxK7bL6ulLh4KezE395gFhjEREZnMx5nn8NWhi7rtUSHtMT60E7zbuNn0\nLWUMYyIiMrqrN8rw7PofZbV1MYPg5mxfxytsC8OYiIiMRpIkrEs7hZO/XNfVpj0YiEHBdwrsyvww\njImIyChyfr+Jle8f0217ujrg1dkhsFdZ1lrDpsAwJiIig1JXajF7zR5ZLf7xngj6WytBHZk/hjER\nERlMyraTskPSCgBvJ4RZ9FrDpsAwJiKiFrt2qxyL3vxBVrOVR1kaAsOYiIhaZNaq3dBoq2W1TYnh\ngrqxTAxjIiJqlp8uFuKVD47Lav+Y2gftffUvE0h1YxgTUS2O6WlwSU76c/m72Pgmr8BD1m36ykzZ\ntvcdTnjl6QcEdWP5GMZEJHP7wvCqrDPwiJqOIoCBTNh9/DK2fP2TrJY8fyA8XB0EdWQdGMZEJOOS\nnKS/nrKGYWzDNNpqzFq1W1Yb2MMP00fdI6YhK8MwJiIZZU52k+pk/d75Txb2ncqV1dYvHGIzaw2b\nAsOYiGS0AYFQZZ3RWyfbUlRaidjX5KsrTR4egLD7/AV1ZL0YxkQkUxYbLztnrKvHxAnohkRJTP0B\n+YXlshpvVzIehjERyagjIlGEmnPEuqupY+J4vthG/Ha1GC+8e1hWS5jUC13v9hLUkW1gGBNRLeqI\nSIavDbr9diWV0g7rFw4R04yNYRgTEdm4Q1l5eCtDfp3Aq7ND0MbTWVBHtodhTERko6olCU+98p2s\ndm+n1oh9NFhQR7aLYUxEZIP+ueUIzl8pktXejAuFowPXGhaBYUxEZEOKyioRu05+u1LEoA4YPaCD\noI4IYBgTEdmM2y/QAoANXGvYLDCMiYis3C9XbmH5lqOy2oSwzhjZ725BHdHtGMZERFZM32yYD+8w\nPwxjIiIr9N2xS3hvZ46sxod3mC+GMRGRFZEkCTNuu10J4GzY3DGMiYisxBvpp3HkpwJZLWnuAHi5\nOwrqiBqLYUxEZOEqKjWYs2avrObX2gXLZ/YX1BE1FcOYiMiCzViZCem2GtcatjwMYyIiC5R7vRRL\n3j4oq43oexceC+8iqCNqCYYxEZGF4e1K1qfBMFar1XjiiSdQWVkJrVaLESNGIDo6WrZPZWUlFi1a\nhDNnzuCOO+7A2rVr4e/vb7SmiYhs0ZHsfLyx47+y2rxxPXBfgLegjshQGgxjBwcHbN68Ga6urqiq\nqsKkSZMwePBg9OzZU7fPtm3b4OHhgW+++QZffPEFVq9ejeTkZKM2TkRkSzgbtm4NhrFCoYCrqysA\nQKPRQKPRQHHbc0wzMzMxb948AMCIESPw4osvQpKkWvsREVHTfPBtDr49cklWe3lWf7Rt5SKoIzKG\nRp0z1mq1GDduHC5evIhJkyYhOFi+1mVeXh78/Pxq3lClgru7OwoLC9GqVSvDd0xEZAM02mrMWrVb\nVlMpFVi/MExMQ2RUjQpjpVKJjIwMFBUVYe7cucjJyUFAQIDu55J0+4X1aHBW7OXlApWq6etmenu7\nN/k11HIcdzE47mKIHvdZK75F7vVSWW3bilFwcrTua25Fj7tITfov6+HhgX79+mHfvn2yMPb19UVu\nbi58fX2h0WhQXFyMO+64o973Kiwsa3Kz3t7uKCgobvLrqGU47mJw3MUQOe6FxWrEv/69rNb3Hh88\nPaY7iovKYc2/Dbby+17XF44Gw/jGjRtQqVTw8PBARUUFDhw4gJkzZ8r2CQ8PR3p6Onr16oWvv/4a\n/fv35/liIqIm0HeB1saEMP4ttRENhnF+fj4SExOh1WohSRJGjhyJsLAwpKSkoHv37hg6dCgiIyOx\ncOFCDBs2DJ6enli7dq0peicisnjZvxXi1a3HZbW/j+yKIT3bCeqIRFBI+k74mkBzDkfYymEMc8Nx\nF4PjLoYpx13k7UqO6WlwSU6CMicb2oBAlMXGQx0RaZLP1sdWft+bfZiaiIgM68sff8O23b/Iakun\n9EYHPw+TfL5jeho8oqbrtlVZZ+ARNR1FgNBAtmUMYyIiE6mWJDxlBmsNuyQn6a+nrGEYC8IwJiIy\ngVVbjyPrt0JZbV3MILg525u8F2VOdpPqZHxcY4uICDWHbr1CQwCVCl6hIXBMTzPI+5ZWVGH6ykxZ\nEHdu54lNieFCghgAtAGBTaqT8XFmTEQ2z1jnUPVdoLVhURjs7MTerlQWGy/79+rqMXECuiGAM2Mi\nonrPoTbHxbziWkE8dlAHbEoMFx7EQM0XjKLUTdB06w5JpYKmW3cUpW7i+WKBODMmIptnyHOolrK6\nkjoikuFrRhjGRGTztAGBUGWd0VtvrO9P52LjF1myWvxjPRHUgQvmUMMYxkRk81pyDlWSJMwwg9uV\nyLIxjInI5qkjIlGEmnPEqpxsaAICURYT1+Bh3I1fnMX3p6/KaqtmP4DWnk5G7JasEcOYiAh/nkP1\n9nZHYQOPZays0uLppD2y2h1uDlgzb6AxWyQrxjAmImqCeWv3okytkdVSFwyBvYo3p1Dz8beHiAzu\njwdotPHzMugDNETKv1mO6SszZUEc1qsdNiWGM4ipxTgzJiKDssZFCCzldiWyXAxjIjIoa1qE4OS5\na0hJOyWrRT0ShH7d2grqiKwVw5iIDMpaFiHgbJhMiWFMRAZliAdoiLTlP2exbdfPstpLM/qinbeb\noI7IFjCMicigLHURAo22GrNW7a5V52yYTIFhTEQG9dcHaChzsqFt5AM0RNJ3SPr1ZwbD2ZF/Isk0\n+JtGRAZnKYsQXL9VgYVvHpDVfFq5YOWs/oI6IlvFMCaTcExPg0ty0p8zpdh4i/hjTdZL32x4Y0IY\nfHw8UNDAE7iIDI1hTEZnjfedkuU68fM1rPtEfrvS0Pv88cTwAEEdETGMyQSs6b5Tsmy8XYnMFcOY\njM5a7jsly/XBNzn49uglWW3++B7o1cVbUEdEcgxjMjpLv++ULBfXGiZLwTAmo7PU+07JskWn7ENJ\neZWs9ursELTxdBbUEVHdGMZkdJZ43ylZrpLyKkSn7KtV52yYzBnDmEzCUu47Jcum7wKt9QuHQKXk\nEodk3hjGRGTxfrl8C8vfOyqrBXdqjZhHgwV1RNQ0DGMismi8XYmsAcOYiCySvtuV/j6yK4b0bCeo\nI6LmYxgTkcXhbJisDcOYiCxG1OrdqNJUy2rPPnk/Ovt7CuqIyDAYxkRk9tSVWsxes6dWnbNhshYM\nYyIya/oOSf8rdhBcnOwFdENkHAxjIjJLv10txgvvHq5V52yYrBHDmIjMTl1rDSsUCgHdEBkfw5iI\nzMbOQxfxYeY5WS0kyBczR3cT1BGRaTCMicgs8HYlsmUMYyIS6oV3D+O3q8Wy2tyI7ri/q4+gjohM\nj09PJ7Iwjulp8AoNQRs/L3iFhsAxPU10S82ira7G9JWZtYJ4U2I4g5hsDmfGRBbEMT1Ntja0KusM\nPKKmowiwqFWx9B2SXj3nAbTycBLQDZF4nBkTWRCX5CT99ZQ1Ju6kea7dKq/z3DCDmGwZZ8ZEFkSZ\nk92kujnRF8IbFoXBzo63KxFxZkxkQbQBgU2qm4PD2fm1griDnwc2JYYziIn+hzNjIgtSFhsvO2es\nq8fECeimYbxdiahxGMZEFkQdEYki1JwjVuZkQxsQiLKYOLO7eCv10zM4eDZPVps4tAuG9blLUEdE\n5o1hTGRh1BGRZhe+f5AkCTNe+a5WnbNhovoxjInIIPQdkn5hel/c5eNmtM90TE+DS3LSn0cJYuPN\n9osKUX0YxkTUIsVllYhZt79W3dizYWu555oIYBgTUQvomw2/GR8KR3ul0T+7vnuuGcZkaRoM49zc\nXCxatAjXrl2DnZ0dJkyYgClTpsj2OXjwIObMmQN/f38AwLBhwzBv3jzjdExEwp365TqSt52sVTfl\nuWFLvuea6HYNhrFSqURiYiKCgoJQUlKC8ePHY8CAAejcubNsv969eyM1NdVojRKReTCX25W0AYFQ\nZZ3RWyeyNA0+9MPHxwdBQUEAADc3N3Ts2BF5eXkNvIqIrM2mL7JqBXHfe3yEXSldFhuvv26m91wT\n1adJ54wvXbqErKwsBAcH1/rZiRMn8Mgjj8DHxwcJCQno0qVLve/l5eUClarp55W8vd2b/BpqOY67\nGOYy7qPjM2rVPksaI6CTv5g1DfBwBl5+GTh7FujWDVi8GB6PP97itzaXcbc1tjzuCkmSpMbsWFpa\nismTJ+Ppp5/G8OHDZT8rKSmBQqGAq6sr9uzZg+XLl2Pnzp31vl9BQXG9P9fH29u9Wa+jluG4i2EO\n467vkPS8cT1wX4C3gG5MwxzG3RbZyrjX9YWjUc+mrqqqQnR0NEaPHl0riIGaw9eurq4AgNDQUGg0\nGty4caMF7RKRSJVV2jrPDVtzEBOJ0uBhakmSsGTJEnTs2BHTpk3Tu09BQQHatGkDhUKBU6dOobq6\nGl5eXgZvloiMT18Ir503AJ5ujgK6IbINDYbx0aNHkZGRgYCAAIwZU3OOKC4uDleuXAEATJw4EV9/\n/TW2bt0KpVIJJycnrFmzBgoFV2MhsiQX84qx7J3Dtep8lCWR8TX6nLGh8Zyx5eC4i2HKcdc3G96Y\nEGaTX6r5+y6GrYx7XeeM+QQuIhv2nx9/Q9ruX2S1dm1c8dJT/QR1RGSbGMZEBmYpixeYy8M7iIhh\nTGRQlrB4wcI3vsf1IrWsxrWGicRiGBMZkDkvXlAtSXiKaw0TmSWGMZEBmeviBfoOSb/0VD+0a+Mq\noBsiul2jHvpBRI1T1yIFohYvuH6ros5zwwxiIvPBmTGRAZXFxsvOGevqAhYv0BfC6xcOgUrJ7+BE\n5oZhTGRA6ohIFKHmHLHuauqYOJOeL/7x7FWs//RsrTrPDROZL4YxkYGpIyKFXazF25WILBPDmMgK\nJG87iVO/XJfVht7vjyeGBQjqiIiagmFMZOE4GyayfAxjIgulL4QXTuyFe9pzxTQiS8MwJrIw5WoN\n5q7dW6vO2TCR5WIYE1kQfbPh12IHwdXJXkA3RGQoDGMiC/BrbhFe2nykVp2zYSLrwDAmMnO8QIvI\n+jGMiczUJ5k/490v5A/vGBzsh6kP3iOoIyIyFoYxkRnibJjItjCMiczI0o0HcbmgVFaLHn8venZp\nI6gjIjIFhjGRGdBoqzFr1e5adc6GiWwDw5hIMH2HpJPmDkBAxzYoKCgW0BERmRrDmEiQgpvlSHjr\nh1p1zoaJbA/DmEgAfbPhDQlhsFMoBHRDRKIxjIlMSN9aw13vugMJT9wnqCMiMgcMYyIT4e1KRFQX\nhjGRkb2efhpHfyqQ1SaP6IqwXu0EdURE5oZhTGQkkiRhxivf1apzNkxEt2MYExmBvkPSL83oi3be\nbgK6ISJzxzAmMqCyCg3mJXOtYSJqGoYxkYHomw2nLgiFvUopoBsisiQMY6IW0rfWcNDfvBD/eC9B\nHRGRpWEYE7UAb1ciIkNgGBM1wzdHfsfWb3+W1Z4YFoCh9/sL6oiILBnDmKiJOBsmIkNjGBM10qsf\nHEP2xZuy2j+m9kF7X3dBHRGRtWAYEzWgSlONqNW7a9U5GyYiQ2EYE9VD3yHpf8UOhosT/69DRIbD\nvyhEeuQXliEx9UdZrY2nE16d/YCgjojImjGMiW6jbza8MSEMCq41TERGwjAm+p/s3wrx6tbjstpD\n/dsjckgnQR0Rka1gGBOhabcrOaanwSU5CcqcbGgDAlEWGw91RKSxWyQiK8YwJpv25cHfsO27X2S1\npVN6o4Ofh979HdPT4BE1XbetyjoDj6jpKAIYyETUbAxjsknVkoSnmrHWsEtykv56yhqGMRE1G8OY\nbM7qD4/j7IVCWW1dzCC4Ods3+FplTnaT6kREjcEwJptRWlGF+cn7ZLXO7Tzx7OT7G/0e2oBAqLLO\n6K0TETUXw5hsgr4LtDYsCoOdXdNuVyqLjZedM9bVY+Ka3RsREcOYrNrFvGIse+ewrDZ2UAc8MqBD\ns95PHRGJItScI9ZdTR0Tx/PFRNQiDGOyWsZaXUkdEcnwJSKDYhiT1fn+dC42fpElq8U/1hNBHVoJ\n6oiIqH4MY7IakiRhRjNuVyIiEq3BMM7NzcWiRYtw7do12NnZYcKECZgyZYpsH0mSsHz5cuzZswdO\nTk5YuXIlgoKCjNY00e02fnEW35++Kqutmv0AWns6CeqIiKjxGgxjpVKJxMREBAUFoaSkBOPHj8eA\nAQPQuXNn3T579+7FhQsXsHPnTpw8eRLLli3Dtm3bjNo4EQBUVmnxdNIeWc3L3RFJcwcI6oiIqOka\nDGMfHx/4+PgAANzc3NCxY0fk5eXJwnjXrl0YO3YsFAoFevbsiaKiIuTn5+teR2QM85P3orRCI6ul\nLhgCe5WdoI6IiJqnSeeML126hKysLAQHB8vqeXl58PX11W37+voiLy+PYUxGkX+zHIlv/SCrhfVq\nh8kjugrqiIioZRodxqWlpYjh3yccAAAPa0lEQVSOjsazzz4LNzc32c8kSaq1f0Nrv3p5uUClUjb2\n43W8vd2b/BpqOXMZ99HxGbVqnyWNEdCJaZjLuNsajrsYtjzujQrjqqoqREdHY/To0Rg+fHitn/v6\n+uLq1T8vnrl69WqDs+LCwrImtlrzH6qgoLjJr6OWMYdxP3nuGlLSTslqUY8EoV+3tsJ7MxZzGHdb\nxHEXw1bGva4vHA2GsSRJWLJkCTp27Ihp06bp3Sc8PBz//ve/MWrUKJw8eRLu7u48RE0GY6yHdxAR\nmYsGw/jo0aPIyMhAQEAAxoypORwYFxeHK1euAAAmTpyI0NBQ7NmzB8OGDYOzszNWrFhh3K7JJmzf\n+ws+P/CbrPbSjL5o5+1WxyuIiCxTg2Hcu3dv/PTTT/Xuo1Ao8I9//MNgTZFt01ZXY+aru2vVORsm\nImvFJ3CRWVn2ziFczCuR1V5/ZjCcHfmrSkTWi3/hyCwUlVYi9rX9slrPzm0QHXmvoI6IiEyHYUzC\n6btAa2NCWIO3xxERWQuGMQlz7vItrHjvqKw2cWgXDOtzl6COiIjEYBiTELxdiYjoTwxjMqldRy/h\n/W9yZLXFT96HLv53COqIiEg8hjGZBNcaJiKqG8OYjO61T07h+M/XZLW18wfC09VBUEdEROaFYUxG\nU67WYO7avbKav7cbXpzRV1BHRETmiWFMRqHvAq23Fw2B0o5rDRMR3Y5hTAZ1+Voplm44KKs91L89\nIod0EtQREZH5YxiTwfB2JSKi5mEYU4sdysrDWxlnZLXo8feiZ5c2gjoiIrIsDGNqEc6GiYhajmFM\nzbL35BW8+2W2rLYyqj98vFwEdUREZLkYxtQkGm01Zq3aLau5OqnwWuxgMQ0REVkBhjE12pavf8Lu\n45dltdQFQ2Cv4u1KREQtwTCmBt0qUdc6N/zEsAAMvd9fUEdERNaFYUz1em7DQVy5Viqrca1hIiLD\nYhiTXpfyS/D8pkOy2sKJvXBPey9BHRERWS+GMdVy+yFphQLYmMDblYiIjIVhTDpHf8rH6+n/ldVe\neToE3br4oKCgWFBXRETWj2FMqJYkPHXbWsNBHVoh/rGegjoiIrItDGMbt2PfeXz6/QVZ7Y24wXBy\n4K8GEZGp8C+ujdK31vCYgR0wZmAHQR0REdkuhrENWrX1OLJ+K5TVNiSEwY63KxERCcEwtiH5N8uR\n+NYPstrciB64v6u3oI6IiAhgGJstx/Q0uCQnQZmTDW1AIMpi46GOiGz2+3F1JSIi88UwNkOO6Wnw\niJqu21ZlnYFH1HQUAU0O5KwLN7DqwxOy2osz+sLf280QrRIZ/IsjkS1iGJshl+Qk/fWUNY3+IydJ\nEmbcdruSv7crXpzRr8X9Ef3BkF8ciWwZw9gMKXOym1S/3TdHfsfWb3+W1dbFDIKbs32LeyP6K0N8\ncSQihrFZ0gYEQpV1Rm+9PlWaakSt3i2rhd3XDpOHdzVke0Q6Lf3iSEQ1GMZmqCw2XnboT1ePiavz\nNes/O4Mfz+TJam8vGgKlHdcaJuNp7hdHIpLjX2ozpI6IRFHqJmi6dYekUkHTrTuKUjfpPex3839r\nDf81iKc9FIhNieEM4mZyTE+DV2gI2vh5wSs0BI7paaJbMltlsfH66/V8cSSi2jgzNlPqiMgGz7nF\n/Ws/bpZUymq8XalleEFS06gjIlGEmnPEuqupY+I4VkRNxDC2QL/mFuGlzUdktWcn34/O7TwFdWQ9\neEFS0zXmiyMR1Y9hbGFuf3iHq5MKr8UOFtSN9eEFSUQkAsPYQvzw36t4+/OzslrS3AHwcncU1JF1\n4gVJRCQCw9jMVVdLeOpV+cM77u/qjbkRPQR1ZN2acyU7EVFLMYzN2Ie7fsbOw7/Lam/Fh8LBXimo\nI+vHC5KISASGsRmqqNRgzhr5WsMTwjpjZL+7BXVkW3hBEhGZGsPYzGz5Khu7T1yR1TYmhEHBtYaJ\niKwWw9hMXLtVjkVvytcaXjqlNzr4eQjqqGFcrYeIyDAYxmZg2TuHcDGvRLfd8U4PPPf33gI7ahgf\njkFEZDgMY4HOXb6FFe8dldVWz3kArTycBHXUeHw4BhGR4TCMBdC31vDQ+/zxxPAAQR01HR+OQURk\nOAxjE8v5/SZWvn9MVnszLhSODpZ1uxIfjkFEZDgMYxPRaKvx3NsHkX+zXFebMrIrQnu2E9hV8/Hh\nGEREhsMwNoEfz17F+k//fJTlPe29sODxnhZ9uxIfjkFEZDgMYyMqq9BgXrL84R0vzeiLdt5ugjoy\nLD4cg4jIMBoM48WLF2P37t1o3bo1Pv/881o/P3jwIObMmQN/f38AwLBhwzBv3jzDd2phPjtwAel7\nz+u2w+9rhyeHdxXYERERmasGw3jcuHF48sknkZCQUOc+vXv3RmpqqkEbs1TXb1Vg4ZsHZLW18wbA\n042rKxERkX4NhnGfPn1w6dIlU/Ri8d7+7Cx+OHNVtz3x/7pgWO+7BHZERESWwCDnjE+cOIFHHnkE\nPj4+SEhIQJcuXQzxthbjwtUivPjuEd22g8oOKdGDLO52JSIiEqPFYRwUFITMzEy4urpiz549mDt3\nLnbu3Nng67y8XKBSNT2svL3dm9OmUWirJSxI2YNzl27pas9N64t+3f0EdmUc5jTutoTjLgbHXQxb\nHvcWh7Gb259XBoeGhuKFF17AjRs30KpVq3pfV1hY1uTP8vZ2R0FBcZNfZwwnfr6GdZ+c0m2393XH\n0r/3hp2dwmx6NBRzGndbwnEXg+Muhq2Me11fOFocxgUFBWjTpg0UCgVOnTqF6upqeHl5tfRtzZa6\nUouYdftQqanW1cx9dSUiIjJvDYZxXFwcDh06hMLCQgwePBjz58+HRqMBAEycOBFff/01tm7dCqVS\nCScnJ6xZs8aiH2ZRn2+P/I4Pvv1Ztx0S1BYzRwcJ7IiIiKyBQpIkScQHN+dwhKjDGLdK1HjmX9/L\naq/ODkEbT2eT9yKCrRw+MjccdzE47mLYyrgb7TC1tfvgmxx8e/TPW7siBnXA6AEdBHZERETWhmFc\nh8vXSrF0w0FZ7V+xg+HixCEjIiLDYrLcRpIkJH10AmcvFOpqs0Z3Q/8gX4FdERGRNWMY/0XWhRtY\n9eEJ3bbPHc7458x+UCntBHZFRETWjmEMoEpTjYS3DuBmSaWuljCpF7rebb23aBERkfmw+TDefyoX\nm/6Tpdvu2bkN5o/vYbW3ZxERkfmx2TAuKa9CdMo+WW35zH7wa+0qqCMiIrJVNhnG2/eex+cHLui2\nR/a7GxPCOotriIiIbJpNhXF+YRkSU3+U1ZKjB8LDxUFQR0RERDYSxpIk4Y0d/8XRnwp0tb+P7Ioh\nPdsJ7IqIiKiG1Yfxucu3sOK9o7ptVycVkuYOgIM91xomIiLzYLVhrK2uxvMbDyH3+p9LNT4zIRg9\nOrYW2BUREVFtVhnGR7Lz8caO/+q2A/w9seiJ+2DH25WIiMgMWVUYl6s1mLt2r6y2bFof3N1W/yoZ\nRERE5sBqwvjLg79h23e/6LYHB9+JqQ8GCuyIiIiocawijL858rssiJPmDoCXu6PAjoiIiBrPKlZA\n6NzOEwAwIawzNiWGm3UQO6anwSs0BG38vOAVGgLH9DTRLRERkWBWMTPu4OeBTYnhottokGN6Gjyi\npuu2VVln4BE1HUUA1BGR4hojIiKhrGJmbClckpP011PWmLgTIiIyJwxjE1LmZDepTkREtoFhbELa\nAP1Xd9dVJyIi28AwNqGy2Hj99Zg4E3dCRETmhGFsQuqISBSlboKmW3dIKhU03bqjKHUTL94iIrJx\nVnE1tSVRR0QyfImISIYzYyIiIsEsPoz5EA0iIrJ0Fn2Ymg/RICIia2DRM2M+RIOIiKyBRYcxH6JB\nRETWwKLDmA/RICIia2DRYcyHaBARkTWw6DDmQzSIiMgaWPTV1AAfokFERJbPomfGRERE1oBhTERE\nJBjDmIiISDCGMRERkWAMYyIiIsEYxkRERIIxjImIiARjGBMREQnGMCYiIhJMIUmSJLoJIiIiW8aZ\nMRERkWAMYyIiIsEYxkRERIIxjImIiARjGBMREQnGMCYiIhLM7MM4NzcXkydPxoMPPohRo0Zh8+bN\noluyKVqtFmPHjkVUVJToVmxGUVERoqOjMXLkSDz44IM4fvy46JZswrvvvotRo0bh4YcfRlxcHNRq\nteiWrNbixYsREhKChx9+WFe7efMmpk2bhuHDh2PatGm4deuWwA5Nz+zDWKlUIjExEV9++SU++ugj\nfPDBBzh37pzotmzGli1b0KlTJ9Ft2JTly5dj0KBB+Oqrr5CRkcHxN4G8vDxs2bIFn3zyCT7//HNo\ntVp88cUXotuyWuPGjcOGDRtktfXr1yMkJAQ7d+5ESEgI1q9fL6g7Mcw+jH18fBAUFAQAcHNzQ8eO\nHZGXlye4K9tw9epV7N69G5GRkaJbsRklJSU4fPiwbswdHBzg4eEhuCvboNVqUVFRAY1Gg4qKCvj4\n+IhuyWr16dMHnp6estquXbswduxYAMDYsWPx7bffimhNGLMP47+6dOkSsrKyEBwcLLoVm7BixQos\nXLgQdnYW9Wti0X7//Xe0atUKixcvxtixY7FkyRKUlZWJbsvqtW3bFtOnT0dYWBgGDhwINzc3DBw4\nUHRbNuX69eu6L0A+Pj64ceOG4I5My2L+ypaWliI6OhrPPvss3NzcRLdj9b777ju0atUK3bt3F92K\nTdFoNDh79iwmTpyIHTt2wNnZ2eYO14lw69Yt7Nq1C7t27cK+fftQXl6OjIwM0W2RDbGIMK6qqkJ0\ndDRGjx6N4cOHi27HJhw7dgyZmZkIDw9HXFwcfvzxRyxYsEB0W1bP19cXvr6+uqM/I0eOxNmzZwV3\nZf0OHDgAf39/tGrVCvb29hg+fDgvnDOx1q1bIz8/HwCQn5+PVq1aCe7ItMw+jCVJwpIlS9CxY0dM\nmzZNdDs2Iz4+Hnv37kVmZibWrFmD/v37Y/Xq1aLbsnre3t7w9fXF+fPnAQA//PADL+AygTvvvBMn\nT55EeXk5JEniuAsQHh6OHTt2AAB27NiBoUOHCu7ItFSiG2jI0aNHkZGRgYCAAIwZMwYAEBcXh9DQ\nUMGdERnH0qVLsWDBAlRVVeGuu+7Cyy+/LLolqxccHIwRI0YgIiICKpUK99xzDx577DHRbVmtuLg4\nHDp0CIWFhRg8eDDmz5+PWbNmITY2FmlpafDz80NKSoroNk2KSygSEREJZvaHqYmIiKwdw5iIiEgw\nhjEREZFgDGMiIiLBGMZERESCMYyJiIgEYxgTEREJxjAmIiIS7P8Bz+L36t92JnsAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e63f4a290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 3000\n",
    "step = 500\n",
    "\n",
    "# Training Data\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "weight = tf.Variable(rng.randn(), name=\"weight\")\n",
    "constant = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n",
    "# Construct a linear model\n",
    "pred = tf.add(tf.multiply(X, weight), constant)\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "#  Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch :\", '%3d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"weight=\", sess.run(weight), \"constant=\", sess.run(constant))\n",
    "\n",
    "    \n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"\\nTraining cost=\", training_cost, \"W=\", sess.run(weight), \"b=\", sess.run(constant), '\\n')\n",
    "\n",
    "    # Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(weight) * train_X + sess.run(constant), label='Fitted line')\n",
    "    plt.title(\"Linear Regression Example\\n\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regresison using inbuilt TensorFlow Estimator\n",
    "\n",
    "Let us see how we can implement different models using the inbuilt estimators. The current example deals with the automobile data where cylinders ,displacement ,\thorsepower, \tweight, \tacceleration are the features ( independent variables) and mpg ( miles per gallon ) is the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cylinders  displacement  horsepower  weight  acceleration   mpg\n",
       "0          8         307.0         130    3504          12.0  18.0\n",
       "1          8         350.0         165    3693          11.5  15.0\n",
       "2          8         318.0         150    3436          11.0  18.0\n",
       "3          8         304.0         150    3433          12.0  16.0\n",
       "4          8         302.0         140    3449          10.5  17.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example dataset \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"mpg.csv\")\n",
    "new_df =df[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration','mpg']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_name=\"mpg\"\n",
    "train_fraction=0.8\n",
    "path=\"mpg_train.csv\"\n",
    "import collections\n",
    "\n",
    "defaults = collections.OrderedDict([\n",
    "    (\"mpg\", [0.0]), (\"cylinders\", [0.0]), (\"displacement\", [0.0]), (\"horsepower\", [0.0]), (\"weight\", [0.0]), (\"acceleration\", [0.0])])\n",
    "\n",
    "def decode_line(line):\n",
    "    \"\"\"Convert a csv line into a (features_dict,label) pair.\"\"\"\n",
    "    # Decode the line to a tuple of items based on the types of\n",
    "    # csv_header.values().\n",
    "    items = tf.decode_csv(line, list(defaults.values()))\n",
    "\n",
    "    # Convert the keys and items to a dict.\n",
    "    pairs = zip(defaults.keys(), items)\n",
    "    features_dict = dict(pairs)\n",
    "\n",
    "    # Remove the label from the features_dict\n",
    "    label = features_dict.pop(y_name)\n",
    "\n",
    "    return features_dict, label\n",
    "def in_training_set(line):\n",
    "    \"\"\"Returns a boolean tensor, true if the line is in the training set.\"\"\"\n",
    "    # If you randomly split the dataset you won't get the same split in both\n",
    "    # sessions if you stop and restart training later. Also a simple\n",
    "    # random split won't work with a dataset that's too big to `.cache()` as\n",
    "    # we are doing here.\n",
    "    num_buckets = 1000000\n",
    "    bucket_id = tf.string_to_hash_bucket_fast(line, num_buckets)\n",
    "    # Use the hash bucket id as a random number that's deterministic per example\n",
    "    return bucket_id < int(train_fraction * num_buckets)\n",
    "\n",
    "def in_test_set(line):\n",
    "    \"\"\"Returns a boolean tensor, true if the line is in the training set.\"\"\"\n",
    "    # Items not in the training set are in the test set.\n",
    "    # This line must use `~` instead of `not` because `not` only works on python\n",
    "    # booleans but we are dealing with symbolic tensors.\n",
    "    return ~in_training_set(line)\n",
    "\n",
    "  \n",
    "base_dataset = (tf.data.TextLineDataset(path))\n",
    "\n",
    "train = (base_dataset.filter(in_training_set).map(decode_line).cache())\n",
    "\n",
    "  # Do the same for the test-set.\n",
    "test = (base_dataset.filter(in_test_set).cache().map(decode_line))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "now, train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpOGVutD\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0e63f0e310>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpOGVutD', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpOGVutD/model.ckpt.\n",
      "INFO:tensorflow:loss = 79898.39, step = 1\n",
      "INFO:tensorflow:global_step/sec: 659.966\n",
      "INFO:tensorflow:loss = 17080.0, step = 101 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 1146.87\n",
      "INFO:tensorflow:loss = 1970.9241, step = 201 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1055.55\n",
      "INFO:tensorflow:loss = 9215.178, step = 301 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1026.69\n",
      "INFO:tensorflow:loss = 10015.696, step = 401 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.32\n",
      "INFO:tensorflow:loss = 2265.4585, step = 501 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1192.42\n",
      "INFO:tensorflow:loss = 7017.116, step = 601 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 568.741\n",
      "INFO:tensorflow:loss = 8210.992, step = 701 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.417\n",
      "INFO:tensorflow:loss = 1850.3433, step = 801 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 1212.74\n",
      "INFO:tensorflow:loss = 7335.9893, step = 901 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1204.66\n",
      "INFO:tensorflow:loss = 8228.87, step = 1001 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 901.631\n",
      "INFO:tensorflow:loss = 1245.0769, step = 1101 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1202.15\n",
      "INFO:tensorflow:loss = 6281.1484, step = 1201 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1116.35\n",
      "INFO:tensorflow:loss = 8629.291, step = 1301 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1006.52\n",
      "INFO:tensorflow:loss = 1968.4078, step = 1401 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1205.62\n",
      "INFO:tensorflow:loss = 7024.749, step = 1501 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1199.82\n",
      "INFO:tensorflow:loss = 7533.9614, step = 1601 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.058\n",
      "INFO:tensorflow:loss = 1626.0045, step = 1701 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 1204.91\n",
      "INFO:tensorflow:loss = 7212.259, step = 1801 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1219.93\n",
      "INFO:tensorflow:loss = 7117.7085, step = 1901 (0.082 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpOGVutD/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7072.2246.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-24-00:53:44\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpOGVutD/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-24-00:53:44\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 40.517525, global_step = 2000, loss = 3362.9546\n",
      "\n",
      "RMS error for the test set: 41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def input_train():\n",
    "  return (\n",
    "      train.shuffle(1000).batch(128)\n",
    "      .repeat().make_one_shot_iterator().get_next())\n",
    "\n",
    "def input_test():\n",
    "  return (test.shuffle(1000).batch(128)\n",
    "          .make_one_shot_iterator().get_next())\n",
    "\n",
    "feature_columns = [\n",
    "tf.feature_column.numeric_column(key=\"cylinders\"),\n",
    "tf.feature_column.numeric_column(key=\"displacement\"),\n",
    "tf.feature_column.numeric_column(key=\"horsepower\"),\n",
    "tf.feature_column.numeric_column(key=\"weight\"),\n",
    "tf.feature_column.numeric_column(key=\"acceleration\")\n",
    "]\n",
    "\n",
    "\n",
    "model = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "STEPS = 2000\n",
    "model.train(input_fn=input_train, steps=STEPS)\n",
    "\n",
    "eval_result = model.evaluate(input_fn=input_test)\n",
    "\n",
    "average_loss = eval_result[\"average_loss\"]\n",
    "\n",
    "print(\"\\nRMS error for the validation dataset: {:.0f}\".format(average_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpOGVutD/model.ckpt-2000\n",
      "{'predictions': array([22.006985], dtype=float32)}\n",
      "{'predictions': array([25.239113], dtype=float32)}\n",
      "{'predictions': array([21.91506], dtype=float32)}\n",
      "{'predictions': array([23.07516], dtype=float32)}\n",
      "{'predictions': array([24.768179], dtype=float32)}\n",
      "{'predictions': array([22.796988], dtype=float32)}\n",
      "{'predictions': array([23.316921], dtype=float32)}\n",
      "{'predictions': array([23.95084], dtype=float32)}\n",
      "{'predictions': array([24.456734], dtype=float32)}\n",
      "{'predictions': array([14.014485], dtype=float32)}\n",
      "{'predictions': array([21.48183], dtype=float32)}\n",
      "{'predictions': array([16.116037], dtype=float32)}\n",
      "{'predictions': array([23.45885], dtype=float32)}\n",
      "{'predictions': array([20.548904], dtype=float32)}\n",
      "{'predictions': array([27.240845], dtype=float32)}\n",
      "{'predictions': array([25.670519], dtype=float32)}\n",
      "{'predictions': array([29.685295], dtype=float32)}\n",
      "{'predictions': array([18.852695], dtype=float32)}\n",
      "{'predictions': array([28.458637], dtype=float32)}\n",
      "{'predictions': array([30.196968], dtype=float32)}\n",
      "132.44543855565865\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"mpg_test.csv\")\n",
    "test_df.columns =['mpg','cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']\n",
    "test_df.head()\n",
    "\n",
    "# Run the model in prediction mode.\n",
    " #18 15 18 16 \n",
    "input_dict = {\n",
    "    \"cylinders\": np.array(test_df['cylinders']),\n",
    "    \"displacement\": np.array(test_df['displacement']),\n",
    "   \"horsepower\": np.array(test_df['horsepower']),\n",
    "   \"weight\": np.array(test_df['weight']),\n",
    "   \"acceleration\": np.array(test_df['acceleration'])\n",
    "}\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    input_dict, shuffle=False)\n",
    "predict_results = model.predict(input_fn=predict_input_fn)\n",
    "\n",
    "true_y = np.array(test_df['mpg'])\n",
    "slno=0\n",
    "pred_y=[]\n",
    "for i in predict_results:\n",
    "  print(i)\n",
    "  pred_y.append(i['predictions'][0])\n",
    "  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"\\nRMS error for the test dataset: {:.0f}\".format(mean_squared_error(true_y, np.array(pred_y))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let us take iris data and classify the data points into different species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpSk5kBu\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0e64fe3150>, '_model_dir': '/tmp/tmpSk5kBu', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From <ipython-input-20-b92877e1254d>:19: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-20-b92877e1254d>:19: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpSk5kBu/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1940432, step = 1\n",
      "INFO:tensorflow:global_step/sec: 656.806\n",
      "INFO:tensorflow:loss = 0.20029837, step = 101 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.256\n",
      "INFO:tensorflow:loss = 0.08565542, step = 201 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.972\n",
      "INFO:tensorflow:loss = 0.07563477, step = 301 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.499\n",
      "INFO:tensorflow:loss = 0.06636871, step = 401 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 583.379\n",
      "INFO:tensorflow:loss = 0.06308911, step = 501 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.505\n",
      "INFO:tensorflow:loss = 0.06091857, step = 601 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 751.574\n",
      "INFO:tensorflow:loss = 0.059661306, step = 701 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.783\n",
      "INFO:tensorflow:loss = 0.05805472, step = 801 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.678\n",
      "INFO:tensorflow:loss = 0.057271775, step = 901 (0.139 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpSk5kBu/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.055383258.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:381: calling predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:454: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpSk5kBu/model.ckpt-1000\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_iris(return_X_y = True)\n",
    "\n",
    "X=data[0]\n",
    "y=data[1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "feats = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "\n",
    "classifier_tf = tf.contrib.learn.DNNClassifier(feature_columns=feats, \n",
    "                                               hidden_units=[50, 50, 50], \n",
    "                                               n_classes=3)\n",
    "classifier_tf.fit(X_train, y_train, steps=1000)\n",
    "\n",
    "predictions = list(classifier_tf.predict(X_test, as_iterable=True))\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Neural Networks in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is essentially a framework for building Deep Learning Neural Networks. Neural neworks are typically organized in layers. Layers are made up of a number of interconnected 'nodes' which contain an 'activation function'. Patterns are presented to the network via the 'input layer', which communicates to one or more 'hidden layers' where the actual processing is done via a system of weighted 'connections'. The hidden layers then link to an 'output layer' where the answer is output as shown in the graphic below.\n",
    "\n",
    "<img src=\"simple_neural_network_header.jpg\">\n",
    "\n",
    "Most ANNs contain some form of 'learning rule' which modifies the weights of the connections according to the input patterns that it is presented with. In a sense, ANNs learn by example as do their biological counterparts; a child learns to recognize dogs from examples of dogs.\n",
    "\n",
    "Although there are many different kinds of learning rules used by neural networks, this demonstration is concerned only with one; the delta rule. The delta rule is often utilized by the most common class of ANNs called 'backpropagational neural networks' (BPNNs). Backpropagation is an abbreviation for the backwards propagation of error.\n",
    "\n",
    "With the delta rule, as with other types of backpropagation, 'learning' is a supervised process that occurs with each cycle or 'epoch' (i.e. each time the network is presented with a new input pattern) through a forward activation flow of outputs, and the backwards error propagation of weight adjustments. More simply, when a neural network is initially presented with a pattern it makes a random 'guess' as to what it might be. It then sees how far its answer was from the actual one and makes an appropriate adjustment to its connection weights.\n",
    "\n",
    "<img src=\"back.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Overview\n",
    "\n",
    "\n",
    "A convolutional neural network is a class of deep, feed-forward networks, composed of one or more convolutional layers with fully connected layers (matching those in typical ANNs) on top. It uses tied weights and pooling layers. In particular, max-pooling is often structured via Fukushima's convolutional architecture. This architecture allows CNNs to take advantage of the 2D structure of input data.\n",
    "\n",
    "CNNs are suitable for processing visual and other two-dimensional data. They have shown superior results in both image and speech applications. They can be trained with standard backpropagation. CNNs are easier to train than other regular, deep, feed-forward neural networks and have many fewer parameters to estimate.\n",
    "\n",
    "\n",
    "#### Example:  MNIST  handwritten digits\n",
    "\n",
    "To understand the neural networks, we will use the most general example of MNIST handwritten digits. This dataset contains 60,000 examples for training and 10,000 examples for testing. \n",
    "For more information visit: http://yann.lecun.com/exdb/mnist/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the implementation above mentioned ideas in tensorflow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "# Training Parameters\n",
    "num_steps = 1000\n",
    "learning_rate = 0.005\n",
    "batch_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 784 \n",
    "# image size  28*28\n",
    "num_classes = 10 \n",
    "# Number of classes  i.e 0-9 digits\n",
    "dropout = 0.25 \n",
    "# Dropout probability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add each layer to the model as mentioned in the diagram. This is where the actual compuational layers are present. This is can be quite complex at the begining. Basically we are basiccaly adding different layers as mentioned in the above picture. Add the layers according to the CNN definition and changed parameters according to the need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def neural_network_function(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    \n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "       \n",
    "        x = x_dict['images']\n",
    "\n",
    "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        layer1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        layer1 = tf.layers.max_pooling2d(layer1, 2, 2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3\n",
    "        layer2 = tf.layers.conv2d(layer1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        layer2 = tf.layers.max_pooling2d(layer2, 2, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fclayer1 = tf.contrib.layers.flatten(layer2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fclayer1 = tf.layers.dense(fclayer1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fclayer1 = tf.layers.dropout(fclayer1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        final_layer = tf.layers.dense(fclayer1, n_classes)\n",
    "\n",
    "    return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since tensorflow estimate api takes input, test and models as functions. write the model function with train and test datasets in it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template) from the official website help\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    #Building the neural network for both train and test sets \n",
    "    \n",
    "    logits_train = neural_network_function(features, num_classes, dropout, reuse=False, is_training=True)\n",
    "    logits_test = neural_network_function(features, num_classes, dropout, reuse=True, is_training=False)\n",
    "    \n",
    "    #Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "    \n",
    "    #If prediction mode, early return - Escapse case\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    #loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    #accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    #return specifications\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp4HW7Kx\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0e7e587090>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmp4HW7Kx', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp4HW7Kx/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3093884, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.40343\n",
      "INFO:tensorflow:loss = 0.20535034, step = 101 (41.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.5154\n",
      "INFO:tensorflow:loss = 0.079633996, step = 201 (39.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.5975\n",
      "INFO:tensorflow:loss = 0.043275163, step = 301 (38.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.44444\n",
      "INFO:tensorflow:loss = 0.034163855, step = 401 (40.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.86772\n",
      "INFO:tensorflow:loss = 0.045177337, step = 501 (53.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.41258\n",
      "INFO:tensorflow:loss = 0.023097202, step = 601 (41.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.62706\n",
      "INFO:tensorflow:loss = 0.029189536, step = 701 (38.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.62175\n",
      "INFO:tensorflow:loss = 0.032899737, step = 801 (38.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.54608\n",
      "INFO:tensorflow:loss = 0.04493556, step = 901 (39.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.6222\n",
      "INFO:tensorflow:loss = 0.07850532, step = 1001 (38.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.22376\n",
      "INFO:tensorflow:loss = 0.021108365, step = 1101 (44.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.12236\n",
      "INFO:tensorflow:loss = 0.023906669, step = 1201 (47.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.01565\n",
      "INFO:tensorflow:loss = 0.05762796, step = 1301 (49.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.17023\n",
      "INFO:tensorflow:loss = 0.00404601, step = 1401 (46.076 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1408 into /tmp/tmp4HW7Kx/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.94814\n",
      "INFO:tensorflow:loss = 0.044385146, step = 1501 (51.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.55948\n",
      "INFO:tensorflow:loss = 0.013067174, step = 1601 (39.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72154\n",
      "INFO:tensorflow:loss = 0.031251617, step = 1701 (36.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.5787\n",
      "INFO:tensorflow:loss = 0.024126295, step = 1801 (38.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.60622\n",
      "INFO:tensorflow:loss = 0.015205041, step = 1901 (38.368 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmp4HW7Kx/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.020865303.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f0e6c99bc10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "\n",
    "model.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train the model with images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-24-00:43:20\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4HW7Kx/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-24-00:43:30\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9889, global_step = 2000, loss = 0.036587868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9889, 'global_step': 2000, 'loss': 0.036587868}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn( x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "                                              batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, test the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b8a3b4e33afb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minput_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'images'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredicted_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "images = mnist.test.images[:3]\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(x={'images': test_images}, shuffle=False)\n",
    "predicted_images = list(model.predict(input_fn))\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(np.reshape(images[i], [28, 28]), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Image prediction:\", predicted_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling up ML using Cloud ML Engine\n",
    "\n",
    "In this notebook, we take a previously developed TensorFlow model to predict taxifare rides and package it up so that it can be run in Cloud MLE. For now, we'll run this on a small dataset. The model that was developed is rather simplistic, and therefore, the accuracy of the model is not great either. However, this notebook illustrates how to package up a TensorFlow model to run it within Cloud ML.\n",
    "\n",
    "Later in the course, we will look at ways to make a more effective machine learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment variables for project and bucket\n",
    "\n",
    "Note that:\n",
    "\n",
    "  Your project id is the unique string that identifies your project (not the project name). You can find this from the GCP Console dashboard's Home page. My dashboard reads: Project ID: cloud-training-demos\n",
    "\n",
    "   Cloud training often involves saving and restoring model files. Therefore, we should create a single-region bucket. If you don't have a bucket already, I suggest that you create one from the GCP console (because it will dynamically check whether the bucket name you want is available)\n",
    "\n",
    "Change the cell below to reflect your Project ID and bucket name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'pds-tutorial-198900 ' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'cloud-t-cmsathwik7vk' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "REPO = \"/content/datalab/training-data-analyst\"\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['REPO'] = REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "echo $BUCKET\n",
    "gsutil -m rm -rf gs://${BUCKET}/taxifare/smallinput/\n",
    "gsutil -m cp ${REPO}/courses/machine_learning/datasets/*.csv gs://${BUCKET}/taxifare/smallinput/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/taxifare/smallinput/taxi_trained\n",
    "JOBNAME=lab3a_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${REPO}/courses/machine_learning/cloudmle/taxifare/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --runtime-version=1.0 \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/taxifare/smallinput/taxi-train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/taxifare/smallinput/taxi-valid*\"  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --num_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/taxifare/smallinput/taxi_trained/export/Servo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"taxifare\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/taxifare/smallinput/taxi_trained/export/Servo | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "gcloud ml-engine predict --model=taxifare --version=v1 --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "References:\n",
    "\n",
    "1. DeveloperCoding http://developercoding.com/tensorflow/\n",
    "2. TensorFlow Examples https://github.com/aymericdamien/TensorFlow-Examples\n",
    "3. Serverless Machine Learning with Tensorflow on Google Cloud Platform  https://www.coursera.org/learn/serverless-machine-learning-gcp/\n",
    "4. Neural Networks and Deep Learning http://neuralnetworksanddeeplearning.com/\n",
    "5. Artificial neural network https://en.wikipedia.org/wiki/Artificial_neural_network\n",
    "6. \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
